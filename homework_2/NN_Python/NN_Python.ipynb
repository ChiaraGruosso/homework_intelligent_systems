{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deef0dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import fmin_cg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8bbcd5",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cabbb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureNormalize(X):\n",
    "    X_norm = X\n",
    "    mu = X.mean(axis = 0)\n",
    "    sigma = X.std(axis = 0)\n",
    "    c = X.shape[1]\n",
    "    for i in range(c):\n",
    "        X_norm[:, i] = (X[:, i] - mu[i]) / sigma[i]\n",
    "    return X_norm, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2c15bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_initialize_weights(architecture_layers_size):\n",
    "    '''\n",
    "    random initialize weights using a uniform distribution\n",
    "    \n",
    "    param: \n",
    "        architecture_layers_size: number of neurons of each NN layer \n",
    "    '''\n",
    "    list_initial_theta = []\n",
    "    np.random.seed(1)\n",
    "    for i in range(len(architecture_layers_size) - 1):\n",
    "        list_initial_theta.insert(i, np.random.rand(architecture_layers_size[i + 1], architecture_layers_size[i] + 1))\n",
    "        print(list_initial_theta[i].shape)\n",
    "    return list_initial_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb8296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73a2b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_gradient(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ecaad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(nn_params, X, y, architecture_layers_size, lam):\n",
    "    m = X.shape[0]\n",
    "    print(nn_params.shape)\n",
    "    \n",
    "    list_nn_params = []\n",
    "    first = 0\n",
    "    for i in range(len(architecture_layers_size) - 1):\n",
    "        dim_r = architecture_layers_size[i+1]\n",
    "        dim_c = architecture_layers_size[i] + 1\n",
    "        # print('dim r:', dim_r)\n",
    "        # print('dim c:', dim_c)\n",
    "        # print('first:', first)\n",
    "        last = first + (dim_r * dim_c)\n",
    "        # print('last:', last-1)\n",
    "        p = nn_params[first:last].reshape((dim_r, dim_c))\n",
    "        # print(p.shape)\n",
    "        list_nn_params.append(p)\n",
    "        first = last\n",
    "        # print((nn_params[first:(dim_r * dim_c)].reshape((dim_r, dim_c))).shape)\n",
    "    \n",
    "    # Forward propagation\n",
    "    list_activation = []\n",
    "    list_z = []\n",
    "#     list_activation.insert(0, np.concatenate((np.ones((m, 1)), X), axis = 1))\n",
    "    list_activation.insert(0, np.hstack((np.ones((m, 1)), X)))\n",
    "    # print('a1:', list_activation[0].shape)\n",
    "    if len(architecture_layers_size) > 2:\n",
    "        for i in range(1, len(architecture_layers_size) - 1):\n",
    "            # print('Theta:', list_nn_params[i - 1].shape)\n",
    "#             list_z.insert(i - 1, np.dot(list_activation[i - 1], np.transpose(list_nn_params[i - 1]))) # matrix multiplication (righe x colonne)\n",
    "            list_z.insert(i - 1, np.matmul(list_activation[i - 1], list_nn_params[i - 1].T))\n",
    "            # print('z:', list_z[i - 1].shape)\n",
    "#             list_activation.insert(i, np.concatenate((np.ones((m, 1)), sigmoid(list_z[i - 1])), axis = 1))\n",
    "            list_activation.insert(i, np.hstack((np.ones((m, 1)), sigmoid(list_z[i - 1]))))\n",
    "            # print('a:', list_activation[i].shape)\n",
    "#     list_z.append(np.dot(list_activation[-1], np.transpose(list_nn_params[-1])))\n",
    "    list_z.append(np.matmul(list_activation[-1], list_nn_params[-1].T))\n",
    "    list_activation.append(sigmoid(list_z[-1]))\n",
    "    # print('Theta ultimo:', list_nn_params[-1].shape)\n",
    "    # print('z ultimo:', list_z[-1].shape)\n",
    "    # print('a ultimo:', list_activation[-1].shape)\n",
    "    \n",
    "    y_vec = np.tile(np.arange(0, architecture_layers_size[-1]), (m, 1)) == np.tile(y, (1, architecture_layers_size[-1]))\n",
    "    # print(y_vec)\n",
    "    cost = - (y_vec * np.log(list_activation[-1])) - ((1 - y_vec) * np.log(1 - list_activation[-1]))\n",
    "    J = np.dot((1 / m), np.sum(cost))\n",
    "    \n",
    "    # regularization\n",
    "    list_theta_excluding_bias = []\n",
    "    for i in range(len(list_nn_params)):\n",
    "#         list_theta_excluding_bias.insert(i, np.copy(list_nn_params[i][:, 1:]))\n",
    "        list_theta_excluding_bias.insert(i, list_nn_params[i][:, 1:].copy())\n",
    "    sum_theta_excluding_bias = 0\n",
    "    for i in range(len(list_theta_excluding_bias)):\n",
    "        sum_theta_excluding_bias = sum_theta_excluding_bias + np.sum(list_theta_excluding_bias[i]**2)\n",
    "    J = J + (lam / (2 * m)) * sum_theta_excluding_bias\n",
    "    \n",
    "    # Back propagation\n",
    "    list_delta = []\n",
    "    for i in range(len(list_nn_params)):\n",
    "        list_delta.insert(i, np.zeros((list_nn_params[i].shape)))\n",
    "        # print(list_delta[i].shape)\n",
    "    # print(len(list_delta))\n",
    "    num_z = len(list_z)\n",
    "    for example in range(m):\n",
    "        list_activation_i = []\n",
    "        list_d = []\n",
    "        list_z_i = []\n",
    "        for a in range(len(list_activation)):\n",
    "            list_activation_i.insert(a, list_activation[a][example, :].copy())\n",
    "            # print('a iesimo:', list_activation_i[a])\n",
    "        y_vec_i = y_vec[example, :].copy()\n",
    "        # print(y_vec_i)\n",
    "        for z in range(num_z - 1):\n",
    "            list_z_i.insert(z, list_z[z][example, :].copy())\n",
    "            # print('z iesimo:', list_z_i[0])\n",
    "        list_d.append(list_activation_i[-1] - y_vec_i)\n",
    "        list_d.insert(-1, np.matmul(list_nn_params[-1].T, list_d[-1]) * sigmoid_gradient(np.hstack((1, list_z_i[-1]))))\n",
    "        if len(architecture_layers_size) > 3:\n",
    "            for k in range(num_z - 2):\n",
    "                list_d.insert(0, np.matmul(list_nn_params[num_z - 2 - k].T, list_d[0][1:]) * sigmoid_gradient(np.hstack((1, list_z_i[num_z - 3 - k]))))\n",
    "        if len(architecture_layers_size) > 2:\n",
    "            for i in range(len(list_delta) - 1):\n",
    "                # print('delta_i:', list_delta[i].shape)\n",
    "                list_delta[i] = list_delta[i] + np.matmul(list_d[i][1:][:, np.newaxis], list_activation_i[i][:, np.newaxis].T)\n",
    "                # print('d_i:', list_d[i][1:][:, np.newaxis].shape)\n",
    "                # print('a_i:', list_activation_i[i][:, np.newaxis].T.shape)\n",
    "        list_delta[-1] = list_delta[-1] + np.matmul(list_d[-1][:, np.newaxis], list_activation_i[-2][:, np.newaxis].T)\n",
    "    \n",
    "    # regularization\n",
    "    list_theta_zeroed_bias = []\n",
    "    list_theta_grad = []\n",
    "    for i in range(len(list_nn_params)):\n",
    "        list_theta_zeroed_bias.insert(i, np.hstack((np.zeros((list_nn_params[i].shape[0], 1)), list_theta_excluding_bias[i])))\n",
    "    for i in range(len(list_nn_params)):\n",
    "        list_theta_grad.insert(i, ((1 / m) * list_delta[i] + (lam / m) * list_theta_zeroed_bias[i]))\n",
    "    \n",
    "    #unroll gradients\n",
    "    nn_params = list_theta_grad[0].flatten()\n",
    "    for i in range(1, len(list_theta_grad)):\n",
    "        nn_params = np.hstack((nn_params, list_theta_grad[i].flatten()))\n",
    "    \n",
    "    return J, nn_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8eb70e6",
   "metadata": {},
   "source": [
    "# Import data from text file and NN train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c88fd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvdata = np.matrix(pd.read_csv(\"iris.csv\", header=None))\n",
    "print('Number of examples:', csvdata.shape[0])\n",
    "num_labels = 3\n",
    "c = csvdata.shape[1]\n",
    "X_complete = np.array(csvdata[:, 0:(c - 1)])\n",
    "y_complete = np.array(csvdata[:, (c - 1)])\n",
    "\n",
    "# print(X_complete[0])\n",
    "# print(y_complete[0])\n",
    "\n",
    "# Generate Training, CV and Test sets\n",
    "set_size = y_complete.size\n",
    "rand_indices = np.random.permutation(set_size)\n",
    "\n",
    "X_complete = X_complete[rand_indices, :]\n",
    "y_complete = y_complete[rand_indices]\n",
    "\n",
    "train_size = np.ceil(set_size * 0.6).astype('uint8')\n",
    "cv_size = np.ceil(set_size * 0.2).astype('uint8')\n",
    "\n",
    "# X = np.copy(X_complete[0:train_size, :])\n",
    "# y = np.copy(y_complete[0:train_size])\n",
    "X = X_complete[0:train_size, :].copy()\n",
    "y = y_complete[0:train_size].copy()\n",
    "\n",
    "# X_cv = np.copy(X_complete[(train_size) : (train_size + cv_size), :])\n",
    "# y_cv = np.copy(y_complete[(train_size) : (train_size + cv_size)])\n",
    "X_cv = X_complete[(train_size) : (train_size + cv_size), :].copy()\n",
    "y_cv = y_complete[(train_size) : (train_size + cv_size)].copy()\n",
    "\n",
    "# X_test = np.copy(X_complete[(train_size + cv_size):, :])\n",
    "# y_test = np.copy(y_complete[(train_size + cv_size):])\n",
    "X_test = X_complete[(train_size + cv_size):, :].copy()\n",
    "y_test = y_complete[(train_size + cv_size):].copy()\n",
    "\n",
    "# Feautures normalization\n",
    "X, mu, sigma = featureNormalize(X)\n",
    "X_cv = np.divide(np.subtract(X_cv, mu), sigma)\n",
    "X_test = np.divide(np.subtract(X_test, mu), sigma)\n",
    "\n",
    "input_layer_size = X.shape[1]\n",
    "# print(input_layer_size)\n",
    "list_hidden_layers = [5, 6, 3]\n",
    "# list_hidden_layers = [4]\n",
    "# list_hidden_layers = [5, 2, 4, 3]\n",
    "lam = 0\n",
    "iterations = 10\n",
    "architecture_layers_size = [input_layer_size, num_labels]\n",
    "for i in range(len(list_hidden_layers)):\n",
    "    architecture_layers_size.insert(i + 1, list_hidden_layers[i])\n",
    "\n",
    "list_initial_theta = rand_initialize_weights(architecture_layers_size)\n",
    "\n",
    "theta = list_initial_theta[0].flatten()\n",
    "for i in range(1, len(list_initial_theta)):\n",
    "    theta = np.hstack((theta, list_initial_theta[i].flatten()))\n",
    "    \n",
    "[J, theta] = fmin_cg(cost_function, x0 = theta, fprime = None, args = (X, y, architecture_layers_size, lam), maxiter = iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58518a96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
